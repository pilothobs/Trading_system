#!/usr/bin/env python3
"""
Analyze Resource Usage Logs

This script analyzes the resource usage logs generated by resource_monitor.py
and provides recommendations on whether a cloud GPU is needed.
"""

import os
import re
import sys
import glob
import argparse
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path

def parse_log_file(log_file):
    """
    Parse a resource usage log file into a DataFrame
    
    Args:
        log_file: Path to the log file
        
    Returns:
        DataFrame with parsed data
    """
    system_data = []
    process_data = []
    
    with open(log_file, 'r') as f:
        lines = f.readlines()
    
    iteration = None
    timestamp = None
    
    for line in lines:
        # Parse timestamp
        timestamp_match = re.match(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3})', line)
        if timestamp_match:
            timestamp = timestamp_match.group(1)
        
        # Parse system info
        system_match = re.search(r'System: (\d+) logical CPUs, (\d+) physical CPUs, ([\d.]+) GB RAM', line)
        if system_match:
            logical_cpus = int(system_match.group(1))
            physical_cpus = int(system_match.group(2))
            total_ram_gb = float(system_match.group(3))
            system_info = {
                'logical_cpus': logical_cpus,
                'physical_cpus': physical_cpus,
                'total_ram_gb': total_ram_gb
            }
            continue
        
        # Parse iteration and system stats
        iteration_match = re.search(r'Iteration (\d+) - System CPU: ([\d.]+)%, Memory: ([\d.]+)%', line)
        if iteration_match:
            iteration = int(iteration_match.group(1))
            cpu_percent = float(iteration_match.group(2))
            memory_percent = float(iteration_match.group(3))
            
            system_data.append({
                'timestamp': timestamp,
                'iteration': iteration,
                'cpu_percent': cpu_percent,
                'memory_percent': memory_percent
            })
            continue
        
        # Parse process info
        process_match = re.search(r'  \d+\. PID (\d+) \(([^)]+)\): CPU ([\d.]+)%, Memory ([\d.]+) MB', line)
        if process_match and iteration is not None:
            pid = int(process_match.group(1))
            name = process_match.group(2)
            cpu_percent = float(process_match.group(3))
            memory_mb = float(process_match.group(4))
            
            process_data.append({
                'timestamp': timestamp,
                'iteration': iteration,
                'pid': pid,
                'name': name,
                'cpu_percent': cpu_percent,
                'memory_mb': memory_mb
            })
            continue
        
        # Parse total for monitored processes
        total_match = re.search(r'Total for monitored processes: CPU ([\d.]+)%, Memory ([\d.]+) MB', line)
        if total_match and iteration is not None:
            total_cpu = float(total_match.group(1))
            total_memory_mb = float(total_match.group(2))
            
            # Add to the last system data entry
            if system_data:
                system_data[-1]['total_cpu'] = total_cpu
                system_data[-1]['total_memory_mb'] = total_memory_mb
    
    system_df = pd.DataFrame(system_data)
    process_df = pd.DataFrame(process_data)
    
    return system_df, process_df, system_info

def analyze_resource_usage(log_file, output_dir=None):
    """
    Analyze resource usage from a log file and generate recommendations
    
    Args:
        log_file: Path to the log file
        output_dir: Directory to save plots and reports
    """
    print(f"Analyzing log file: {log_file}")
    
    # Parse the log file
    system_df, process_df, system_info = parse_log_file(log_file)
    
    if system_df.empty:
        print("Error: No data found in log file")
        return
    
    # Create output directory if specified
    if output_dir:
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
    else:
        output_path = Path(log_file).parent
    
    # Basic statistics
    duration = len(system_df)
    max_cpu = system_df['cpu_percent'].max()
    avg_cpu = system_df['cpu_percent'].mean()
    max_memory_percent = system_df['memory_percent'].max()
    avg_memory_percent = system_df['memory_percent'].mean()
    
    if 'total_cpu' in system_df.columns:
        max_total_cpu = system_df['total_cpu'].max()
        avg_total_cpu = system_df['total_cpu'].mean()
        max_total_memory = system_df['total_memory_mb'].max()
        avg_total_memory = system_df['total_memory_mb'].mean()
    else:
        max_total_cpu = avg_total_cpu = max_total_memory = avg_total_memory = 0
    
    # Generate plots
    plt.figure(figsize=(12, 8))
    
    # CPU usage plot
    plt.subplot(2, 1, 1)
    plt.plot(system_df['iteration'], system_df['cpu_percent'], label='System CPU')
    if 'total_cpu' in system_df.columns:
        plt.plot(system_df['iteration'], system_df['total_cpu'], label='Monitored Processes CPU')
    plt.title('CPU Usage Over Time')
    plt.xlabel('Iteration')
    plt.ylabel('CPU Usage (%)')
    plt.legend()
    plt.grid(True)
    
    # Memory usage plot
    plt.subplot(2, 1, 2)
    plt.plot(system_df['iteration'], system_df['memory_percent'], label='System Memory %')
    if 'total_memory_mb' in system_df.columns:
        # Convert MB to percentage of total
        memory_percent = system_df['total_memory_mb'] / (system_info['total_ram_gb'] * 1024) * 100
        plt.plot(system_df['iteration'], memory_percent, label='Monitored Processes Memory %')
    plt.title('Memory Usage Over Time')
    plt.xlabel('Iteration')
    plt.ylabel('Memory Usage (%)')
    plt.legend()
    plt.grid(True)
    
    plt.tight_layout()
    plot_file = output_path / f"{Path(log_file).stem}_plot.png"
    plt.savefig(plot_file)
    print(f"Plot saved to: {plot_file}")
    
    # Process-specific analysis
    if not process_df.empty:
        # Group by process name and calculate average resource usage
        process_summary = process_df.groupby('name').agg({
            'cpu_percent': ['mean', 'max'],
            'memory_mb': ['mean', 'max']
        }).reset_index()
        
        process_summary.columns = ['name', 'avg_cpu', 'max_cpu', 'avg_memory_mb', 'max_memory_mb']
        process_summary = process_summary.sort_values('avg_cpu', ascending=False)
        
        # Save process summary
        summary_file = output_path / f"{Path(log_file).stem}_process_summary.csv"
        process_summary.to_csv(summary_file, index=False)
        print(f"Process summary saved to: {summary_file}")
    
    # Generate recommendations
    recommendations = []
    
    # CPU recommendations
    if max_cpu > 90:
        recommendations.append("⚠️ System CPU usage exceeded 90%. Consider upgrading CPU or optimizing code.")
    elif max_cpu > 70:
        recommendations.append("⚡ System CPU usage exceeded 70%. Monitor performance during peak trading times.")
    else:
        recommendations.append("✅ CPU usage is acceptable.")
    
    # Memory recommendations
    if max_memory_percent > 90:
        recommendations.append("⚠️ System memory usage exceeded 90%. Consider adding more RAM.")
    elif max_memory_percent > 70:
        recommendations.append("⚡ System memory usage exceeded 70%. Monitor memory during peak trading times.")
    else:
        recommendations.append("✅ Memory usage is acceptable.")
    
    # GPU recommendations
    if max_total_cpu > 200:  # Using more than 2 cores worth of CPU
        recommendations.append("🔥 High CPU usage detected. A GPU could significantly improve performance for ML models.")
    elif max_total_cpu > 100:  # Using more than 1 core worth of CPU
        recommendations.append("⚡ Moderate CPU usage detected. A GPU might improve performance for complex ML models.")
    else:
        recommendations.append("✅ Current CPU usage doesn't indicate a need for GPU acceleration.")
    
    # Print summary
    print("\n" + "="*50)
    print("RESOURCE USAGE SUMMARY")
    print("="*50)
    print(f"System: {system_info['logical_cpus']} logical CPUs, {system_info['physical_cpus']} physical CPUs, {system_info['total_ram_gb']:.2f} GB RAM")
    print(f"Duration: {duration} iterations")
    print("\nSystem-wide Usage:")
    print(f"  Max CPU: {max_cpu:.1f}%, Avg CPU: {avg_cpu:.1f}%")
    print(f"  Max Memory: {max_memory_percent:.1f}%, Avg Memory: {avg_memory_percent:.1f}%")
    
    if 'total_cpu' in system_df.columns:
        print("\nMonitored Processes Usage:")
        print(f"  Max CPU: {max_total_cpu:.1f}%, Avg CPU: {avg_total_cpu:.1f}%")
        print(f"  Max Memory: {max_total_memory:.1f} MB, Avg Memory: {avg_total_memory:.1f} MB")
    
    print("\nRECOMMENDATIONS:")
    for rec in recommendations:
        print(f"  {rec}")
    
    # Save summary to file
    summary_file = output_path / f"{Path(log_file).stem}_summary.txt"
    with open(summary_file, 'w') as f:
        f.write("RESOURCE USAGE SUMMARY\n")
        f.write("="*50 + "\n")
        f.write(f"System: {system_info['logical_cpus']} logical CPUs, {system_info['physical_cpus']} physical CPUs, {system_info['total_ram_gb']:.2f} GB RAM\n")
        f.write(f"Duration: {duration} iterations\n\n")
        f.write("System-wide Usage:\n")
        f.write(f"  Max CPU: {max_cpu:.1f}%, Avg CPU: {avg_cpu:.1f}%\n")
        f.write(f"  Max Memory: {max_memory_percent:.1f}%, Avg Memory: {avg_memory_percent:.1f}%\n\n")
        
        if 'total_cpu' in system_df.columns:
            f.write("Monitored Processes Usage:\n")
            f.write(f"  Max CPU: {max_total_cpu:.1f}%, Avg CPU: {avg_total_cpu:.1f}%\n")
            f.write(f"  Max Memory: {max_total_memory:.1f} MB, Avg Memory: {avg_total_memory:.1f} MB\n\n")
        
        f.write("RECOMMENDATIONS:\n")
        for rec in recommendations:
            f.write(f"  {rec}\n")
    
    print(f"Summary saved to: {summary_file}")
    
    return {
        'max_cpu': max_cpu,
        'avg_cpu': avg_cpu,
        'max_memory_percent': max_memory_percent,
        'avg_memory_percent': avg_memory_percent,
        'recommendations': recommendations
    }

def main():
    parser = argparse.ArgumentParser(description='Analyze resource usage logs')
    parser.add_argument('log_file', nargs='?', help='Path to the log file to analyze')
    parser.add_argument('--latest', action='store_true', help='Analyze the latest log file')
    parser.add_argument('--output-dir', help='Directory to save plots and reports')
    
    args = parser.parse_args()
    
    # Determine log file to analyze
    if args.latest:
        log_dir = Path(__file__).parent.parent.parent / "logs"
        log_files = list(log_dir.glob("resource_usage_*.log"))
        if not log_files:
            print("Error: No resource usage log files found")
            return
        
        # Sort by modification time (newest first)
        log_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        log_file = log_files[0]
    elif args.log_file:
        log_file = Path(args.log_file)
        if not log_file.exists():
            print(f"Error: Log file {log_file} does not exist")
            return
    else:
        print("Error: Either specify a log file or use --latest")
        return
    
    analyze_resource_usage(log_file, args.output_dir)

if __name__ == "__main__":
    main() 